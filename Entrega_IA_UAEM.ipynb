{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Entrega_IA_UAEM.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkaMlLKBxEau"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/25/Logo_uaem_morelos.png\" style=\"width: 400px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFK8BwiLxEay"
      },
      "source": [
        "<h2><center>Instituto de Investigación en Ciencias Básicas y Aplicadas (IICBA)</center></h2>\n",
        "<h2><center>Centro de Investigación en Ciencias (CINC)</center></h2>\n",
        "\n",
        "<h3><center>Curso: Inteligencia Artificial</center>\n",
        "<center>Profesor: Mauricio Rosales Rivera</center>\n",
        "<center>Mini Proyecto</center></h3>\n",
        "    \n",
        "<h3><center>Fecha: Noviembre 25, 2020</center></h3>\n",
        "\n",
        "---\n",
        "\n",
        "<h3>Calificación: </h3>\n",
        "\n",
        "---\n",
        "<h4><center>Estudiantes</center></h4>\n",
        "<h4>Nombres:</h4>\n",
        "\n",
        "Bravo Martínez Ariel Miguel \n",
        "\n",
        "Ehrlich López Alexandra\n",
        "\n",
        "Hernández Jaramillo Kevin \n",
        "\n",
        "\n",
        "<h4>Matrículas:</h4>\n",
        "\n",
        "10018737\n",
        "\n",
        "10018739\n",
        "\n",
        "10018742\n",
        "\n",
        "\n",
        "<h4>Link del repositorio:</h4>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbT8PHx1xEaz"
      },
      "source": [
        "## <font color=\"brown\">Proyecto - Inteligencia Artificial</font>\n",
        "\n",
        "---\n",
        "\n",
        "Indicaciones: El proyecto seleccionado será desarrollado siguiendo ciertas condiciones. Deberán seguir la estructura recomendada (pero podrán cambiar títulos, es sólo una sugerencia) y podrán añadir secciones en caso de que ser necesario.\n",
        "\n",
        "* La entrega límite de entrega de la notebook será: Viernes 11 de Diciembre.\n",
        "* Deberán realizar una exposición (entre 10 y 20 minutos a lo mucho), donde proporcionen una explicación acerca de la metodología implementada y los resultados obtenidos.\n",
        "\n",
        "Esta notebook deberá contener el nombre completo, matrícula y el link correspondiente al GitHub de cada integrante.\n",
        "En caso de no tener la información aquí solicitada, no se evaluará el proyecto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AU-gQW_xEaz"
      },
      "source": [
        "<a id=\"general\"></a>\n",
        "### Contenido\n",
        "\n",
        "-----\n",
        "\n",
        "1. [Objetivo](#a)\n",
        "\n",
        "2. [Exploración de Datos](#b)\n",
        "    * Detección de valores faltantes\n",
        "    * Agregando valores\n",
        "    * Visualizando datos\n",
        "    * Preprocesamiento de datos\n",
        "        * Reducción de dimensiones\n",
        "        \n",
        "-----\n",
        "3. [Selección de modelos](#c)\n",
        "    * Aprendizaje No Supervisado / Supervisado\n",
        "        * Selección de modelo\n",
        "        * Selección de hiperparámetros\n",
        "        * Entrenamiento\n",
        "        * Prueba\n",
        "        * Resultados\n",
        "-----\n",
        "\n",
        "4. [Conclusiones](#d)\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI9tW39vxEaz"
      },
      "source": [
        "<a id=\"a\"></a>\n",
        "### 1. Objetivo\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#general)\n",
        "\n",
        "Intentar presentar un enfoque completo para modelar problemas, que va desde el análisis exploratorio de datos hasta la aplicación de técnicas de aprendizaje supervisado y no supervisado a nuestros datos.\n",
        "\n",
        "El contenido de esta notebook está dirigido principalmente para entender mejor las etapas que se realizan en los problemas de Ciencia de Datos y Aprendizaje Máquina (y posiblemente en Aprendizaje Profundo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIJrorFmxJY5"
      },
      "source": [
        "**OBJETIVO**\r\n",
        "\r\n",
        "En la actualidad el reconocimiento facial ha experimentado una gran cantidad de avances y, sobre todo, ha evolucionado en la aplicación de su tecnología en distintos procesos cotidianos. El reconocimiento facial es una tecnología capaz de identificar o verificar a un sujeto a través de una imagen, vídeo o cualquier elemento audiovisual de su rostro. Generalmente, esta identificación es usada para acceder a una aplicación, sistema o servicio.\r\n",
        "\r\n",
        "El uso del reconocimiento facial se centra en la verificación o autenticación de rostros y, con ello, de personas. Esta tecnología se utiliza, por ejemplo, en situaciones como:\r\n",
        "\r\n",
        " - Segundo factor de autenticación, para añadir un extra de seguridad, en cualquier proceso de log-in (inicio de sesión).\r\n",
        " - Acceso a una aplicación móvil sin necesidad de contraseña.\r\n",
        " - Acceso a servicios online previamente contratados (inicio de sesión en plataformas online, por ejemplo.).\r\n",
        " - Acceso a un recinto (oficinas, eventos, instalaciones de cualquier tipo…).\r\n",
        " - Método de pago, tanto en tiendas físicas como online.\r\n",
        " - Acceso a un dispositivo bloqueado.\r\n",
        " - Check-in en servicios turísticos (Aeropuertos, hoteles…).\r\n",
        "\r\n",
        " Nuetro objetivo en este proyecto es dado el video de una persona, ingresar la información de esta en nuestra base de datos para posteriormente poder reconocerla en una foto.\r\n",
        "\r\n",
        " Además agregamos un extra en el que la idea no es identificar a la persona si no la emoción que denota su expresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLIl8Q-RxEa0"
      },
      "source": [
        "<a id=\"b\"></a>\n",
        "### 2. Exploración de Datos\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#general)\n",
        "\n",
        "En esta sección se trata de realizar una breve explicación del conjunto de datos a utilizar. Así como tener un orden al momento de importar librerías, mostrar gráficos del EDA y preprocesamiento de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4brbNAxy3wM"
      },
      "source": [
        "**Exploración de Datos**\r\n",
        "\r\n",
        "Nuestro conjunto de datos es un grupo de videos de distintas personas, para un mejor resulta de nuestro reconocimiento es indispensable que las tomas del video se encuentren en distintos lugares, con diferentes luces, si es posible agregar distintos peinados y en caso de utilizar lentes agregar unas tomas con ellos para que el modelo este preparado para reconocer a la persona utilizando lentes. \r\n",
        "\r\n",
        "Este conjunto de videos únicamente nos evitará la tarea de estar agregando foto por foto a nuestra base, ya que podemos realizar este proceso automáticamente, una vez que se tenga el video tomamos 1000 fotografías de este (es decir tendremos 1000 fotografías de cada persona), se van a escalar para que todas las fotografías tengan el mismo tamaño además de que las preparará en blanco y negro para que nuestros modelos puedan tomar la información de esta base de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxNxap70xEa1"
      },
      "source": [
        "<a id=\"c\"></a>\n",
        "### 3. Selección de modelos\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#general)\n",
        "\n",
        "En esta sección se trata de realizar una breve explicación de la metodología de aprendizaje automático. En caso de aplicar un **pipeline** de aprendizaje no supervisado y / o supervisado, que tenga un orden claro y expliquen el porqué de su aplicación con lo que han percibido de sus datos. \n",
        "\n",
        "El modelo seleccionado, qué parámetros o hiperparámetros eligieron, el porqué entrenaron con cierto tamaño de muestra y los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2KpowL_0g6R"
      },
      "source": [
        "**MODELOS**\r\n",
        "\r\n",
        "En esta situación utilizamos 3 modelos que son brindados por OpenCV, todos los modelos requieren de un aprendizaje supervisado:\r\n",
        "\r\n",
        " - **EIGENFACES**\r\n",
        "\r\n",
        "Este modelo emplea el método PCA el cuál es una técnica de Extracción de Características donde combinamos las entradas de una manera específica y podemos eliminar algunas de las variables “menos importantes” manteniendo la parte más importante todas las variables. Según la documentación de OpenCV: 'La idea es que un conjunto de datos de alta dimensión a menudo se describe mediante variables correlacionadas y, por lo tanto, solo unas pocas dimensiones significativas explican la mayor parte de la información.’.\r\n",
        "\r\n",
        "En resumen lo que hace el algoritmo es:\r\n",
        "\r\n",
        "- Estandarizar los datos de entrada (ó Normalización de las Variables)\r\n",
        "\r\n",
        "- Obtener los autovectores y autovalores de la matriz de covarianza\r\n",
        "\r\n",
        "- Ordenar los autovalores de mayor a menor y elegir los “k” autovectores que se correspondan con los autovectores “k” más grandes (donde “k” es el número de dimensiones del nuevo subespacio de características).\r\n",
        "\r\n",
        "- Construir la matriz de proyección W con los “k” autovectores seleccionados\r\n",
        "\r\n",
        "- Transformamos el dataset original “X estandarizado” vía W para obtener las nuevas características k-dimensionales\r\n",
        "\r\n",
        "\r\n",
        "- **FISHERFACES**\r\n",
        " \r\n",
        "Es una mejora del método eigenfaces, es un método que se encarga del reconocimiento de caras, teniendo en cuenta como se refleja la luz y las expresiones faciales.Clasifica y reduce la dimensión de las caras utilizando el método Discriminante Lineal de Fisher(FLD) y PCA (conocido como Eigenfaces). Este método crea una proyección lineal que maximiza las diferentes imágenes de caras proyectadas. El método FLD se basa en el reconocimiento de patrones y aprendizaje de máquinas para encontrar una combinación lineal de rasgos que caracterizan o separan dos o más clases de objetos o eventos.\r\n",
        "\r\n",
        "- **LBPH**\r\n",
        "\r\n",
        "LBPH (Histogramas de Patrones Binarios Locales) presenta mejoras respecto a los métodos anteriores, ya que es más robusto ante cambios de iluminación, este método etiqueta los píxeles de una imagen mediante el umbral de la vecindad de cada píxel y considera el resultado como un número binario. En la documentación de OpenCV tenemos 'La idea es no mirar la imagen completa como un vector de alta dimensión, sino describir solo las características locales de un objeto'\r\n",
        "\r\n",
        "El algoritmo usa 4 parámetros:\r\n",
        "Radio, Vecinos, Grid X, Grid Y\r\n",
        "\r\n",
        "Y la idea de su funcionamiento es:\r\n",
        "\r\n",
        "- Entrenamiento: necesitamos utilizar un conjunto de datos con las imágenes faciales de las personas que queremos reconocer. También necesitamos establecer una identificación (puede ser un número o el nombre de la persona) para cada imagen, por lo que el algoritmo usará esta información para reconocer una imagen de entrada y darle una salida. Las imágenes de la misma persona deben tener la misma identificación.\r\n",
        "\r\n",
        "- Primero se crea una imagen intermedia que describa mejor la imagen original, resaltando las características faciales. Para ello, el algoritmo utiliza un concepto sliding window, basado en los parámetros radio y vecinos.\r\n",
        "\r\n",
        "- Extrayendo los histogramas: Ahora, usando la imagen generada en el último paso, podemos usar los parámetros Grid X y Grid Y para dividir la imagen en múltiples cuadrículas\r\n",
        "\r\n",
        "- Reconocimiento facial: En este paso, el algoritmo ya está entrenado. Cada histograma creado se utiliza para representar cada imagen del conjunto de datos de entrenamiento. Entonces, dada una imagen de entrada, realizamos los pasos nuevamente para esta nueva imagen y creamos un histograma que representa la imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk7AyEY9xEa1"
      },
      "source": [
        "<a id=\"d\"></a>\n",
        "### 4. Conclusiones\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#general)\n",
        "\n",
        "De su análisis, qué pueden concluir? Qué posibilidades extras pudieran aplicarse o con qué finalidad realizaron el trabajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "185f9Bg75b3L"
      },
      "source": [
        "**Nuestros resultados**\r\n",
        "\r\n",
        "Se planteó un problema de la vida real el típico 'eres idéntico a tu hermano' y las situaciones de poder desbloquer por reconocimiento facial su celular nos hizo pensar '¿Realmente son tan iguales?', así que lo que queríamos era, poder distinguir en una foto a dos hermanos (en este caso utilizamos a Alexa y Hanna) el resultado, con un entrenamiento de 1000 fotografías de sus rostros fue posible identificar en una fotografía quien es cual, se cree que con una mayor cantidad de fotografía los valores que se obtienen de compatibilidad serán más pequeños y por lo tanto los resultados mucho más precisos.\r\n",
        "\r\n",
        "También implementamos los modelos para el reconocimiento de emociones, en este caso el primer entrenamiento se realizo con 100 fotos, los resultados, para felicidad y sorpresa fueron buenos desde este punto, sin embargo para las emociones de tristeza y enojo los resultados solían estar cambiado, esto debido a que varios rasgos aparecen cuando denotamos ambas emociones, tuvimos que aumentar el entrenamiento a 500 fotografías de cada emoción, los resultados fueron increliblemente mejores.\r\n"
      ]
    }
  ]
}